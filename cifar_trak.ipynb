{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import wget\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss, Conv2d, BatchNorm2d\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "import torchvision\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.lib.format import open_memmap\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = \"cifar_checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet9\n",
    "class Mul(torch.nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super(Mul, self).__init__()\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.weight\n",
    "\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Residual(torch.nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(Residual, self).__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.module(x)\n",
    "\n",
    "\n",
    "def construct_rn9(num_classes=10):\n",
    "    def conv_bn(\n",
    "        channels_in, channels_out, kernel_size=3, stride=1, padding=1, groups=1\n",
    "    ):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                channels_in,\n",
    "                channels_out,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                groups=groups,\n",
    "                bias=False,\n",
    "            ),\n",
    "            torch.nn.BatchNorm2d(channels_out),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    model = torch.nn.Sequential(\n",
    "        conv_bn(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "        conv_bn(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "        Residual(torch.nn.Sequential(conv_bn(128, 128), conv_bn(128, 128))),\n",
    "        conv_bn(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "        torch.nn.MaxPool2d(2),\n",
    "        Residual(torch.nn.Sequential(conv_bn(256, 256), conv_bn(256, 256))),\n",
    "        conv_bn(256, 128, kernel_size=3, stride=1, padding=0),\n",
    "        torch.nn.AdaptiveMaxPool2d((1, 1)),\n",
    "        Flatten(),\n",
    "        torch.nn.Linear(128, num_classes, bias=False),\n",
    "        Mul(0.2),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(\n",
    "    batch_size=256, num_workers=8, split=\"train\", shuffle=False, augment=True\n",
    "):\n",
    "    if augment:\n",
    "        transforms = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.RandomHorizontalFlip(),\n",
    "                torchvision.transforms.RandomAffine(0),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(\n",
    "                    (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.201)\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        transforms = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(\n",
    "                    (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.201)\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    is_train = split == \"train\"\n",
    "    dataset = torchvision.datasets.CIFAR10(\n",
    "        root=\"/tmp/cifar/\", download=True, train=is_train, transform=transforms\n",
    "    )\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_files = sorted(list(Path(f\"./{CHECKPOINT_DIR}\").rglob(\"*.pt\")))\n",
    "ckpts = [torch.load(ckpt, map_location=\"cpu\") for ckpt in ckpt_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = construct_rn9().to(memory_format=torch.channels_last).cuda()\n",
    "model.load_state_dict(ckpts[-1])\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625053a1c25044ebb4c751259af04f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.8%\n"
     ]
    }
   ],
   "source": [
    "loader = get_dataloader(split=\"val\", augment=False)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_correct, total_num = 0.0, 0.0\n",
    "    for ims, labs in tqdm(loader):\n",
    "        ims = ims.cuda()\n",
    "        labs = labs.cuda()\n",
    "        with autocast():\n",
    "            out = model(ims)\n",
    "            total_correct += out.argmax(1).eq(labs).sum().cpu().item()\n",
    "            total_num += ims.shape[0]\n",
    "\n",
    "    print(f\"Accuracy: {total_correct / total_num * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "loader_train = get_dataloader(batch_size=batch_size, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:STORE:No existing model IDs in /home/frank/trak_results.\n",
      "INFO:STORE:No existing TRAK scores in /home/frank/trak_results.\n"
     ]
    }
   ],
   "source": [
    "from trak import TRAKer\n",
    "\n",
    "traker = TRAKer(\n",
    "    model=model,\n",
    "    task=\"image_classification\",\n",
    "    proj_dim=4096,\n",
    "    train_set_size=len(loader_train.dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for model_id, ckpt in enumerate(tqdm(ckpts)):\n",
    "        traker.load_checkpoint(ckpt, model_id=model_id)\n",
    "        for batch in tqdm(loader_train):\n",
    "            batch = [x.cuda() for x in batch]\n",
    "            traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n",
    "    traker.finalize_features()\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_targets = get_dataloader(batch_size=batch_size, split=\"val\", augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id, ckpt in enumerate(tqdm(ckpts)):\n",
    "    traker.start_scoring_checkpoint(\n",
    "        exp_name=\"quickstart\",\n",
    "        checkpoint=ckpt,\n",
    "        model_id=model_id,\n",
    "        num_targets=len(loader_targets.dataset),\n",
    "    )\n",
    "    for batch in loader_targets:\n",
    "        batch = [x.cuda() for x in batch]\n",
    "        traker.score(batch=batch, num_samples=batch[0].shape[0])\n",
    "\n",
    "scores = traker.finalize_scores(exp_name=\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_scores = open_memmap(\"./trak_results/scores/quickstart.mmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = torchvision.datasets.CIFAR10(root=\"/tmp/cifar/\", download=True, train=True)\n",
    "ds_val = torchvision.datasets.CIFAR10(root=\"/tmp/cifar/\", download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR=\"images\"\n",
    "NUM_IMAGES = 10\n",
    "NUM_SAMPLES = 5\n",
    "\n",
    "indices = range(NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices:\n",
    "    fig, axs = plt.subplots(ncols=(NUM_IMAGES + 1), figsize=(NUM_IMAGES * 2, 2))\n",
    "    axs[0].imshow(ds_val[i][0])\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[0].set_title(f\"Target \\n Class: {ds_val[i][1]}\")\n",
    "    top_scorers = np.where(scores[:, i] > 0)[0]\n",
    "    top_scorers = scores[:, i].argsort()[-NUM_IMAGES:][::-1]\n",
    "    \n",
    "    for ii, train_im_ind in enumerate(top_scorers):\n",
    "        axs[ii + 1].set_title(f\"{scores[train_im_ind, i]:.2f} \\n Class: {ds_train[train_im_ind][1]}\")\n",
    "        axs[ii + 1].imshow(ds_train[train_im_ind][0])\n",
    "        axs[ii + 1].axis(\"off\")\n",
    "        \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices:\n",
    "    fig, axs = plt.subplots(ncols=(NUM_IMAGES + 1), figsize=(NUM_IMAGES * 2, 2))\n",
    "    axs[0].imshow(ds_val[i][0])\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[0].set_title(f\"Target \\n Class: {ds_val[i][1]}\")\n",
    "    low_scorers = np.where(scores[:, i] < 0)[0]\n",
    "    low_scorers = scores[:, i].argsort()[:NUM_IMAGES][::-1]\n",
    "    \n",
    "    for ii, train_im_ind in enumerate(low_scorers):\n",
    "        axs[ii + 1].set_title(f\"{scores[train_im_ind, i]:.2f} \\n Class: {ds_train[train_im_ind][1]}\")\n",
    "        axs[ii + 1].imshow(ds_train[train_im_ind][0])\n",
    "        axs[ii + 1].axis(\"off\")\n",
    "        \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"./{IMAGE_DIR}\", exist_ok=True)\n",
    "\n",
    "for i in indices:\n",
    "    top_scorers = np.where(scores[:, i] > 0)[0]\n",
    "    top_scorers = scores[:, i].argsort()[-NUM_IMAGES:][::-1]\n",
    "    low_scorers = np.where(scores[:, i] < 0)[0]\n",
    "    low_scorers = scores[:, i].argsort()[:NUM_IMAGES][::-1]\n",
    "\n",
    "    transform = transforms.ToTensor()\n",
    "    image = transform(ds_val[i][0])\n",
    "    torchvision.utils.save_image(image, f\"./{IMAGE_DIR}/{i}_{ds_val[i][1]}_target_.jpg\")\n",
    "    \n",
    "    for ii, train_im_ind in enumerate(top_scorers):\n",
    "        image = transform(ds_val[i][0])\n",
    "        torchvision.utils.save_image(image, f\"./{IMAGE_DIR}/{i}_{ds_val[i][1]}_{scores[train_im_ind, i]:.2f}_.jpg\")\n",
    "\n",
    "    for ii, train_im_ind in enumerate(low_scorers):\n",
    "        image = transform(ds_val[i][0])\n",
    "        torchvision.utils.save_image(image, f\"./{IMAGE_DIR}/{i}_{ds_val[i][1]}_{scores[train_im_ind, i]:.2f}_.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_scorers = 10\n",
    "indices = range(50)\n",
    "\n",
    "for i in indices:\n",
    "    top_scorers = np.where(scores[:, i] > 0)[0]\n",
    "    top_scorers = scores[:, i].argsort()[-num_top_scorers:][::-1]\n",
    "\n",
    "    transform = transforms.ToTensor()\n",
    "    image = transform(ds_val[i][0])\n",
    "    torchvision.utils.save_image(image, f\"target_{i}_{ds_val[i][1]}.jpg\")\n",
    "    \n",
    "    for ii, train_im_ind in enumerate(top_scorers):\n",
    "        image = transform(ds_val[i][0])\n",
    "        torchvision.utils.save_image(image, f\"{i}_{ds_val[i][1]}_{scores[train_im_ind, i]:.2f}.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
